{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93ec391f-444c-4eab-96c3-50de905dbae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "import PIL.ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76d03cff-c6b6-4cc2-aea8-b407bae2eb75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21d21de2-70d8-4eec-9ac0-76856d74ebb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (60000, 28, 28)\n",
      "y_train.shape: (60000, 1)\n",
      "X_test.shape: (10000, 28, 28)\n",
      "y_test.shape: (10000, 1)\n",
      "\n",
      "Image 21 label: [0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect the dataset\n",
    "\n",
    "# Shapes\n",
    "print(f\"X_train.shape: {X_train.shape}\")\n",
    "print(f\"y_train.shape: {y_train.shape}\")\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "print(f\"y_test.shape: {y_test.shape}\")\n",
    "print(\"\")\n",
    "\n",
    "# Show an example image and the corresponding label\n",
    "idx = 21\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(X_train[idx], cmap=\"gray\")\n",
    "print(f\"Image {idx} label: {y_train[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b716442c-7037-4e22-a1d3-f8672e75bbe0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape: (60000, 10)\n",
      "y_test.shape: (10000, 10)\n",
      "\n",
      "Image 21 label: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Encode the targets\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y_train)\n",
    "\n",
    "# Reshape the image size\n",
    "y_train = enc.transform(y_train).reshape((-1, 10)).todense()\n",
    "y_test = enc.transform(y_test).reshape((-1, 10)).todense()\n",
    "\n",
    "print(f\"y_train.shape: {y_train.shape}\")\n",
    "print(f\"y_test.shape: {y_test.shape}\")\n",
    "print(\"\")\n",
    "\n",
    "print(f\"Image {idx} label: {y_train[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "951a72dc-abee-4b45-a6be-669c863b4523",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " normalization_1 (Normalizat  (None, 784)              1569      \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                15700     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,479\n",
      "Trainable params: 15,910\n",
      "Non-trainable params: 1,569\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "flattening_layer = layers.Flatten()\n",
    "\n",
    "# Normalise the data using a normalisation layer\n",
    "normalisation_layer = layers.Normalization(axis=-1)\n",
    "normalisation_layer.adapt(flattening_layer(X_train))\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(28, 28)),\n",
    "    flattening_layer,\n",
    "    normalisation_layer,\n",
    "    layers.Dense(20, activation=\"relu\"),\n",
    "    # Number of neurons matches the number of classes\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2432cb8d-56a1-4426-9b40-a74f92f2c421",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3188/3188 - 9s - loss: 0.3486 - accuracy: 0.9033 - val_loss: 0.2183 - val_accuracy: 0.9423 - 9s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "3188/3188 - 8s - loss: 0.2388 - accuracy: 0.9409 - val_loss: 0.2259 - val_accuracy: 0.9463 - 8s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "3188/3188 - 7s - loss: 0.2226 - accuracy: 0.9464 - val_loss: 0.2322 - val_accuracy: 0.9484 - 7s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "3188/3188 - 8s - loss: 0.2045 - accuracy: 0.9519 - val_loss: 0.2382 - val_accuracy: 0.9478 - 8s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "3188/3188 - 8s - loss: 0.1996 - accuracy: 0.9532 - val_loss: 0.2670 - val_accuracy: 0.9467 - 8s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "3188/3188 - 8s - loss: 0.1937 - accuracy: 0.9553 - val_loss: 0.2583 - val_accuracy: 0.9516 - 8s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "3188/3188 - 7s - loss: 0.1874 - accuracy: 0.9567 - val_loss: 0.2720 - val_accuracy: 0.9508 - 7s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "3188/3188 - 8s - loss: 0.1808 - accuracy: 0.9585 - val_loss: 0.2946 - val_accuracy: 0.9477 - 8s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "3188/3188 - 7s - loss: 0.1741 - accuracy: 0.9598 - val_loss: 0.3086 - val_accuracy: 0.9481 - 7s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "3188/3188 - 7s - loss: 0.1738 - accuracy: 0.9613 - val_loss: 0.3045 - val_accuracy: 0.9478 - 7s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "# Use early stopping to prevent overfitting\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    # Monitor validation loss \n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.01,\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    verbose=2,\n",
    "    callbacks=es,\n",
    "    validation_split=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb7319-ffc2-44dd-83e1-ea49bb16f823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Examine the training\n",
    "\n",
    "\n",
    "def add_metric(axs, column, history, metric):\n",
    "    train_metrics = history.history[metric]\n",
    "    val_metrics = history.history[\"val_\" + metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    \n",
    "    axs[column].plot(epochs, train_metrics)\n",
    "    axs[column].plot(epochs, val_metrics)\n",
    "    axs[column].set_title(\"Training and validation \" + metric)\n",
    "    axs[column].set_xlabel(\"Epochs\")\n",
    "    axs[column].set_ylabel(metric)\n",
    "    axs[column].legend([\"train_\" + metric, \"val_\" + metric])\n",
    "    \n",
    "# Create the figure and add metrics\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16,8))\n",
    "add_metric(axs, 0, history, \"loss\")\n",
    "add_metric(axs, 1, history, \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb04535c-5788-46e9-a6c6-f638beb73300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ce653-19a2-4f6c-b298-74e67789e671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4780ad53-3c82-4e90-8725-7157fad9730b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test the model with own handwriting\n",
    "\n",
    "\n",
    "file = \"test_4.png\"\n",
    "#Build in function in keras + properties\n",
    "img = keras.utils.load_img(\n",
    "    file,\n",
    "    color_mode=\"grayscale\",\n",
    "    interpolation=\"bilinear\",\n",
    "    target_size=(28,28),\n",
    ")\n",
    "\n",
    "# Invert the colors, as this is how the training set is\n",
    "img = PIL.ImageOps.invert(img)\n",
    "\n",
    "# Convert the image into numpy array -> network understands this\n",
    "img_array = keras.utils.img_to_array(\n",
    "    img, \n",
    "    data_format=\"channels_first\",\n",
    ")\n",
    "\n",
    "# Visualise\n",
    "print(f\"img_array.shape: {img_array.shape}\")\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img_array[0], cmap=\"gray\")\n",
    "\n",
    "# Make the prediction\n",
    "pred = model.predict(img_array)\n",
    "\n",
    "# The predicted label is the one with the highest probability\n",
    "pred_label = np.argmax(pred, axis=1)\n",
    "print(f\"pred: {pred}\")\n",
    "print(f\"pred_label: {pred_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daece0a2-008f-44e8-aa13-f594685c3a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
